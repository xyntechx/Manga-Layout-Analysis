{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Manga Layout Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvSDlr5yPqyU"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKJV3yaVMRhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4f8f5c-2bda-4230-ae12-7bc727787d4e"
      },
      "source": [
        "!pip3 uninstall keras-nightly\n",
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 install keras==2.1.6\n",
        "!pip3 install tensorflow==1.15.0\n",
        "!pip3 install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: keras-nightly 2.5.0.dev2021032900\n",
            "Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras_nightly-2.5.0.dev2021032900.dist-info/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/applications/resnet50.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/network.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/topology.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/initializers.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/layers/experimental/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/layers/experimental/preprocessing/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/objectives.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/optimizers/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/optimizers/schedules/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/utils/test_utils.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
            "Found existing installation: tensorflow 2.5.0\n",
            "Uninstalling tensorflow-2.5.0:\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting keras==2.1.6\n",
            "  Downloading Keras-2.1.6-py2.py3-none-any.whl (339 kB)\n",
            "\u001b[K     |████████████████████████████████| 339 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.13)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.1.6) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.1.6\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 27 kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.34.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 69.4 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.6.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.5.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=322caf52e90d203d8b28030c09f1f418347523b46931f4ea5610f6ba578ede1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oztxkItMb67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08d735d-8479-4de0-e3bd-c1d646f22a0a"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 125.23 MiB | 32.70 MiB/s, done.\n",
            "Resolving deltas: 100% (562/562), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa61M3fOMhdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90442f6b-ad3c-48f3-9252-707f40666b91"
      },
      "source": [
        "%cd Mask_RCNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNR9tCIWMmNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3e2fd9-6352-42d5-eb5a-cc0a39ee14ca"
      },
      "source": [
        "!python setup.py install\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mask_rcnn.egg-info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mrcnn\n",
            "copying mrcnn/config.py -> build/lib/mrcnn\n",
            "copying mrcnn/model.py -> build/lib/mrcnn\n",
            "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mask_rcnn-2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.7.egg\n",
            "Copying mask_rcnn-2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding mask-rcnn 2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.23)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
            "Requirement already satisfied: tensorflow>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.1.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.10.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n",
            "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.34.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (57.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.5.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.7.4.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.5)\n",
            "Collecting ipyparallel\n",
            "  Downloading ipyparallel-6.3.0-py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting nose>=0.10.1\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.6.1)\n",
            "Requirement already satisfied: Sphinx>=1.3 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.6.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.10.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.2.5)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (21.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (0.17.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (1.2.4)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.9.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.11.3)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->IPython[all]->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->IPython[all]->-r requirements.txt (line 12)) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from ipyparallel->IPython[all]->-r requirements.txt (line 12)) (22.1.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->IPython[all]->-r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->IPython[all]->-r requirements.txt (line 12)) (1.0.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->IPython[all]->-r requirements.txt (line 12)) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->IPython[all]->-r requirements.txt (line 12)) (1.7.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->IPython[all]->-r requirements.txt (line 12)) (0.10.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->IPython[all]->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->IPython[all]->-r requirements.txt (line 12)) (1.9.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 12)) (1.1.5)\n",
            "Installing collected packages: nose, ipyparallel\n",
            "Successfully installed ipyparallel-6.3.0 nose-1.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVw_z1VjO1nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b881bf07-9fbc-4279-b2d6-b82232f55ea2"
      },
      "source": [
        "!pip install elementpath\n",
        "!pip install manga109api"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elementpath\n",
            "  Downloading elementpath-2.2.3-py3-none-any.whl (149 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 92 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 102 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 122 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 133 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 143 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 149 kB 8.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: elementpath\n",
            "Successfully installed elementpath-2.2.3\n",
            "Collecting manga109api\n",
            "  Downloading manga109api-0.3.1-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: manga109api\n",
            "Successfully installed manga109api-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq7ge8sqO2kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cd15a7-db84-4a8d-aeae-4a8b1e312735"
      },
      "source": [
        "import elementpath\n",
        "from xml.etree import ElementTree\n",
        "import manga109api\n",
        "from google.colab import files\n",
        "from os import listdir\n",
        "from numpy import zeros, asarray, expand_dims, mean\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset, extract_bboxes, compute_ap\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
        "import matplotlib.pyplot as pyplot\n",
        "from matplotlib.patches import Rectangle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jIldJh4T9fo"
      },
      "source": [
        "root_dir = \"/content/drive/MyDrive/NRP/Project/Manga109/\"\n",
        "p = manga109api.Parser(root_dir=root_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i5QUXQDPboM"
      },
      "source": [
        "# Reformat Manga109 annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjmrNZ3GXLWx"
      },
      "source": [
        "# %cd /content\n",
        "# for book in p.books:\n",
        "#   tree = ElementTree.parse(root_dir + \"annotations/\" + book + \".xml\")\n",
        "#   root = tree.getroot()\n",
        "\n",
        "#   %mkdir $book\n",
        "#   %cd /content/$book\n",
        "\n",
        "#   for page in root.findall('.//page'):\n",
        "#     new_xml = page\n",
        "#     b_xml = ElementTree.tostring(new_xml)\n",
        "#     with open(\"new_\" + book + str(page.attrib[\"index\"]) + \".xml\", \"wb\") as f:\n",
        "#       f.write(b_xml)\n",
        "  \n",
        "#   %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g90nU93IYLqo"
      },
      "source": [
        "# for book in p.books:\n",
        "#   !zip -r /content/$book /content/$book"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qfL7lwheT6e"
      },
      "source": [
        "# print('\\n'.join(p.books))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwQ9GyH4QKmI"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTO-V6wgDDET"
      },
      "source": [
        "class MangaDataset(Dataset):\n",
        "  # def load_dataset(self, dataset_dir, is_train=True):\n",
        "  def load_dataset(self, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"face\")\n",
        "    self.add_class(\"dataset\", 2, \"text\")\n",
        "\n",
        "    for book in p.books:\n",
        "      images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "      annotations_dir = root_dir + \"/annotations/\" + book + \"/\"\n",
        "\n",
        "      for img in listdir(images_dir):\n",
        "        image_id = img[:-4]\n",
        "      \n",
        "        tree = ElementTree.parse(annotations_dir + \"new_\" + book + str(int(image_id)) + \".xml\")\n",
        "        root = tree.getroot()\n",
        "        faces = []\n",
        "        texts = []\n",
        "\n",
        "        for face in root.findall(\".//face\"):\n",
        "          faces.append(face)\n",
        "        \n",
        "        for text in root.findall(\".//text\"):\n",
        "          texts.append(text)\n",
        "        \n",
        "        if len(faces) < 1: #if there are no faces\n",
        "          continue\n",
        "        \n",
        "        if len(texts) < 1: #if there are no texts\n",
        "          continue\n",
        " \n",
        "        if is_train and int(image_id) >= 50:\n",
        "          continue\n",
        "\n",
        "        if not is_train and int(image_id) < 50:\n",
        "          continue\n",
        "        \n",
        "        img_path = images_dir + img\n",
        "        ann_path = annotations_dir + \"new_\" + book + str(int(image_id)) + \".xml\"\n",
        "\n",
        "        self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0,1,2])\n",
        "\n",
        "\n",
        "  def extract_boxes(self, filename):\n",
        "    tree = ElementTree.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "\n",
        "    for box in root.findall(\".//face\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"face\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//text\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"text\"]\n",
        "      boxes.append(coors)\n",
        "\n",
        "    page_att = root.attrib\n",
        "    width = int(page_att['width'])\n",
        "    height = int(page_att['height'])\n",
        "\n",
        "    return boxes, width, height\n",
        "\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    path = info[\"annotation\"]\n",
        "    boxes, w, h = self.extract_boxes(path)\n",
        "    \n",
        "    masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\n",
        "    class_ids = []\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "      box = boxes[i]\n",
        "      row_s, row_e = box[1], box[3]\n",
        "      col_s, col_e = box[0], box[2]\n",
        "\n",
        "      if box[4] == \"face\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 1\n",
        "        class_ids.append(self.class_names.index('face'))\n",
        "\n",
        "      elif box[4] == \"text\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 2\n",
        "        class_ids.append(self.class_names.index('text'))\n",
        "\n",
        "    return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info[\"path\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQY5a2ZtVZd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec398c50-ecce-4df3-b92b-2a7b3dc8b79f"
      },
      "source": [
        "# train set\n",
        "train_set = MangaDataset()\n",
        "train_set.load_dataset(is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        " \n",
        "# test/val set\n",
        "test_set = MangaDataset()\n",
        "test_set.load_dataset(is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 5050\n",
            "Test: 4856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suboEjk0mTvL"
      },
      "source": [
        "# load an image and mask\n",
        "image_id = 1\n",
        "image = train_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "print(mask.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9LK6YXgA4A"
      },
      "source": [
        "# display image with masks and bounding boxes\n",
        "bbox = extract_bboxes(mask)\n",
        "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kxl7xZvfVRf"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iCDgc7KfYpw"
      },
      "source": [
        "class MangaConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 2\n",
        "  STEPS_PER_EPOCH = 131"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMDpJv8dgCfv"
      },
      "source": [
        "config = MangaConfig()\n",
        "model = MaskRCNN(mode='training', model_dir='/content', config=config)\n",
        "# model.load_weights('/content/drive/MyDrive/NRP/Project/mask_rcnn_coco.h5',\n",
        "#                    by_name=True,\n",
        "#                    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/NRP/Project/face_speech_0.001_20_heads.h5',\n",
        "                   by_name=True,\n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_set, test_set, learning_rate=0.0001, epochs=40, layers=\"all\")\n",
        "\n",
        "# model naming: [classes]_[learning_rate]_[epochs]_[layers]\n",
        "\n",
        "# LEARNING_RATE = 0.001\n",
        "\n",
        "# We could follow this training with further epochs that fine-tune all of the weights in the model.\n",
        "# This could be achieved by using a smaller learning rate and changing the ‘layer’ argument from ‘heads’ to ‘all’.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_esT8GtjQnpU"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKR7ueWM41Yj"
      },
      "source": [
        "class PredictionConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 2\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGwpuPD045Gw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa630a4-48af-497c-bc5b-6aeec526d17c"
      },
      "source": [
        "cfg = PredictionConfig()\n",
        "model = MaskRCNN(mode='inference', model_dir='/content', config=cfg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1944: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35C0dWQC4-bR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e56d0e-438e-4bf2-aebf-4d4310fe37c0"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/NRP/Project/FaceSpeech/model_2.h5', by_name=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e2b_whw5Rqj"
      },
      "source": [
        "def evaluate_model(dataset, model, cfg):\n",
        "  APs = []\n",
        "  for image_id in dataset.image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "    scaled_image = mold_image(image, cfg)\n",
        "    sample = expand_dims(scaled_image, 0)\n",
        "    yhat = model.detect(sample, verbose=0)\n",
        "    r = yhat[0]\n",
        "\n",
        "    AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "\n",
        "  mAP = mean(APs)\n",
        "  return mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3fmfY2Q5VFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5ccee3-b1f9-4def-af83-b9575a68a361"
      },
      "source": [
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train mAP: 0.772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i72u9JmBQu7r"
      },
      "source": [
        "# Detect in New Photos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxF2V7GfoMJX"
      },
      "source": [
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "  for i in range(n_images):\n",
        "    image = dataset.load_image(i)\n",
        "    mask, _ = dataset.load_mask(i)\n",
        "    scaled_image = mold_image(image, cfg)\n",
        "    sample = expand_dims(scaled_image, 0)\n",
        "\n",
        "    yhat = model.detect(sample, verbose=0)[0]\n",
        "\n",
        "    pyplot.subplot(n_images, 2, i*2+1)\n",
        "    pyplot.imshow(image)\n",
        "    pyplot.title('Actual')\n",
        "\n",
        "    for j in range(mask.shape[2]):\n",
        "      pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "\n",
        "    pyplot.subplot(n_images, 2, i*2+2)\n",
        "    pyplot.imshow(image)\n",
        "    pyplot.title('Predicted')\n",
        "    ax = pyplot.gca()\n",
        "\n",
        "    for box in yhat['rois']:\n",
        "      y1, x1, y2, x2 = box\n",
        "      width, height = x2 - x1, y2 - y1\n",
        "\n",
        "      rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtu7lTcqpV_9"
      },
      "source": [
        "# Credits\n",
        "\n",
        "[Kangaroo](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/)\n",
        "\n",
        "[Matterport Mask RCNN](https://github.com/matterport/Mask_RCNN)\n",
        "\n",
        "[Manga109](http://www.manga109.org/en/index.html)"
      ]
    }
  ]
}