{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Manga Layout Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# About\n",
        "\n",
        "This research project for the 2021 Nanyang Research Programme (NRP) by Nanyang Technological University aims to segment character faces and speech bubbles of manga pages, associating each character face to the speech bubble of said character based on the distance between the two classes. In doing so, the project hopes to lay the foundation for easy translation and adaptation of manga into movie scripts, novels, and other literature pieces."
      ],
      "metadata": {
        "id": "rPWiFXSXf_Mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation"
      ],
      "metadata": {
        "id": "TvSDlr5yPqyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip3 uninstall keras-nightly\n",
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 install keras==2.1.6\n",
        "!pip3 install tensorflow==1.15.0\n",
        "!pip3 install h5py==2.10.0"
      ],
      "outputs": [],
      "metadata": {
        "id": "TKJV3yaVMRhe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "outputs": [],
      "metadata": {
        "id": "3oztxkItMb67"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd Mask_RCNN"
      ],
      "outputs": [],
      "metadata": {
        "id": "Wa61M3fOMhdS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python setup.py install\n",
        "!pip install -r requirements.txt"
      ],
      "outputs": [],
      "metadata": {
        "id": "sNR9tCIWMmNf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install elementpath\n",
        "!pip install manga109api"
      ],
      "outputs": [],
      "metadata": {
        "id": "GVw_z1VjO1nb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import elementpath\n",
        "from xml.etree import ElementTree\n",
        "import manga109api\n",
        "from google.colab import files\n",
        "from os import listdir\n",
        "from numpy import zeros, asarray, expand_dims, mean\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset, extract_bboxes, compute_ap\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
        "import matplotlib.pyplot as pyplot\n",
        "from matplotlib.patches import Rectangle, Arrow\n",
        "import math"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "metadata": {
        "id": "Fq7ge8sqO2kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4243d34b-ad9c-45c5-81cd-2671dac7f0bf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "root_dir = \"/content/drive/MyDrive/NRP/Project/Manga109/\"\n",
        "p = manga109api.Parser(root_dir=root_dir)"
      ],
      "outputs": [],
      "metadata": {
        "id": "_jIldJh4T9fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reformat Manga109 annotations"
      ],
      "metadata": {
        "id": "1i5QUXQDPboM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content\n",
        "for book in p.books:\n",
        "  tree = ElementTree.parse(root_dir + \"annotations/\" + book + \".xml\")\n",
        "  root = tree.getroot()\n",
        "\n",
        "  %mkdir $book\n",
        "  %cd /content/$book\n",
        "\n",
        "  for page in root.findall('.//page'):\n",
        "    new_xml = page\n",
        "    b_xml = ElementTree.tostring(new_xml)\n",
        "    with open(\"new_\" + book + str(page.attrib[\"index\"]) + \".xml\", \"wb\") as f:\n",
        "      f.write(b_xml)\n",
        "  \n",
        "  %cd /content"
      ],
      "outputs": [],
      "metadata": {
        "id": "yjmrNZ3GXLWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for book in p.books:\n",
        "  !zip -r /content/$book /content/$book"
      ],
      "outputs": [],
      "metadata": {
        "id": "g90nU93IYLqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('\\n'.join(p.books))"
      ],
      "outputs": [],
      "metadata": {
        "id": "6qfL7lwheT6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "BwQ9GyH4QKmI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "class MangaDataset(Dataset):\n",
        "  def load_dataset(self, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"face\")\n",
        "    self.add_class(\"dataset\", 2, \"text\")\n",
        "    self.add_class(\"dataset\", 3, \"frame\")\n",
        "\n",
        "    last_image_id = 0\n",
        "\n",
        "    for book in sorted(p.books):\n",
        "      images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "      annotations_dir = root_dir + \"annotations/\" + book + \"/\"\n",
        "\n",
        "      for img in sorted(listdir(images_dir)):\n",
        "        og_image_id = int(img[:-4])\n",
        "        image_id = int(img[:-4]) + last_image_id\n",
        "      \n",
        "        tree = ElementTree.parse(annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\")\n",
        "        root = tree.getroot()\n",
        "        faces = []\n",
        "        texts = []\n",
        "        frames = []\n",
        "\n",
        "        for face in root.findall(\".//face\"):\n",
        "          faces.append(face)\n",
        "        \n",
        "        for text in root.findall(\".//text\"):\n",
        "          texts.append(text)\n",
        "        \n",
        "        for frame in root.findall(\".//frame\"):\n",
        "          frames.append(frame)\n",
        "        \n",
        "        if (not faces) or (not texts) or (not frames): #if there are no faces\n",
        "          continue\n",
        "\n",
        "        if is_train and og_image_id >= 50:\n",
        "          continue\n",
        "\n",
        "        if not is_train and og_image_id < 50:\n",
        "          continue\n",
        "        \n",
        "        img_path = images_dir + img\n",
        "        ann_path = annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\"\n",
        "\n",
        "        self.add_image(\"dataset\", image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0, 1, 2, 3])\n",
        "\n",
        "      last_image_id = image_id + 1\n",
        "\n",
        "\n",
        "  def extract_boxes(self, filename):\n",
        "    tree = ElementTree.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "\n",
        "    for box in root.findall(\".//face\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"face\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//text\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"text\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//frame\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"frame\"]\n",
        "      boxes.append(coors)\n",
        "\n",
        "    page_att = root.attrib\n",
        "    width = int(page_att['width'])\n",
        "    height = int(page_att['height'])\n",
        "\n",
        "    return boxes, width, height\n",
        "\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    path = info[\"annotation\"]\n",
        "    boxes, w, h = self.extract_boxes(path)\n",
        "    \n",
        "    masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\n",
        "    class_ids = []\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "      box = boxes[i]\n",
        "      row_s, row_e = box[1], box[3]\n",
        "      col_s, col_e = box[0], box[2]\n",
        "\n",
        "      if box[4] == \"face\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 1\n",
        "        class_ids.append(self.class_names.index('face'))\n",
        "\n",
        "      elif box[4] == \"text\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 2\n",
        "        class_ids.append(self.class_names.index('text'))\n",
        "      \n",
        "      elif box[4] == \"frame\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 3\n",
        "        class_ids.append(self.class_names.index('frame'))\n",
        "\n",
        "    return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info[\"path\"]"
      ],
      "outputs": [],
      "metadata": {
        "id": "uTO-V6wgDDET"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# train set\n",
        "train_set = MangaDataset()\n",
        "train_set.load_dataset(is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        " \n",
        "# test/val set\n",
        "test_set = MangaDataset()\n",
        "test_set.load_dataset(is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 5048\n",
            "Test: 4855\n"
          ]
        }
      ],
      "metadata": {
        "id": "GQY5a2ZtVZd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59682c6-69f0-452a-8758-5b7eccefcf70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load an image and mask\n",
        "image_id = 1\n",
        "image = train_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "print(mask.shape)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3_0BF1ZhHvro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# display image with masks and bounding boxes\n",
        "bbox = extract_bboxes(mask)\n",
        "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "outputs": [],
      "metadata": {
        "id": "bf9LK6YXgA4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "5Kxl7xZvfVRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "class MangaConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  STEPS_PER_EPOCH = 131"
      ],
      "outputs": [],
      "metadata": {
        "id": "6iCDgc7KfYpw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "config = MangaConfig()\n",
        "model = MaskRCNN(mode='training', model_dir='/content', config=config)\n",
        "\n",
        "model.load_weights('/content/manga_cfg20210801T0730/mask_rcnn_manga_cfg_0040.h5',\n",
        "                   by_name=True,\n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_set, test_set, learning_rate=0.000001, epochs=40, layers=\"all\")\n",
        "\n",
        "# config.LEARNING_RATE = 0.001"
      ],
      "outputs": [],
      "metadata": {
        "id": "rMDpJv8dgCfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "_esT8GtjQnpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class PredictionConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "sKR7ueWM41Yj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cfg = PredictionConfig()\n",
        "model = MaskRCNN(mode='inference', model_dir='/content', config=cfg)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DGwpuPD045Gw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.load_weights('/content/manga_cfg20210801T0730/mask_rcnn_manga_cfg_0040.h5', by_name=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "35C0dWQC4-bR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def evaluate_model(dataset, model, cfg):\n",
        "  APs = []\n",
        "  for image_id in dataset.image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "    scaled_image = mold_image(image, cfg)\n",
        "    sample = expand_dims(scaled_image, 0)\n",
        "    yhat = model.detect(sample, verbose=0)\n",
        "    r = yhat[0]\n",
        "\n",
        "    AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "\n",
        "  mAP = mean(APs)\n",
        "  return mAP"
      ],
      "outputs": [],
      "metadata": {
        "id": "3e2b_whw5Rqj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "\n",
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "outputs": [],
      "metadata": {
        "id": "d3fmfY2Q5VFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Associate Face to Text\n",
        "\n",
        "Now: version with only face and text (without frame)\n",
        "\n",
        "Code improved version (See Notes)"
      ],
      "metadata": {
        "id": "ji8U486_kHF7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def arrow_face_text(dataset, image_id, cfg, model):\n",
        "  image = dataset.load_image(image_id)\n",
        "  mask, _ = dataset.load_mask(image_id)\n",
        "  scaled_image = mold_image(image, cfg)\n",
        "  sample = expand_dims(scaled_image, 0)\n",
        "\n",
        "  yhat = model.detect(sample, verbose=0)[0]\n",
        "  rois = list(yhat['rois'])\n",
        "  class_ids = list(yhat['class_ids'])\n",
        "\n",
        "  for j in range(mask.shape[2]):\n",
        "    pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "  \n",
        "  pyplot.subplot(111)\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title('Face to Text')\n",
        "\n",
        "  ax = pyplot.gca()\n",
        "\n",
        "  face_centers = []\n",
        "  text_centers = []\n",
        "  count = 0\n",
        "\n",
        "  for id in class_ids:\n",
        "    box = rois[count]\n",
        "    count += 1\n",
        "\n",
        "    y1, x1, y2, x2 = box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "\n",
        "    rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    if id == 1:\n",
        "      face_x = (x1 + x2)//2\n",
        "      face_y = (y1 + y2)//2\n",
        "      face_center = [face_x, face_y]\n",
        "      face_centers.append(face_center)\n",
        "    elif id == 2:\n",
        "      text_x = (x1 + x2)//2\n",
        "      text_y = (y1 + y2)//2\n",
        "      text_center = [text_x, text_y]\n",
        "      text_centers.append(text_center)\n",
        "    \n",
        "  faces_to_texts = []\n",
        "\n",
        "  for face in face_centers:\n",
        "    if text_centers:\n",
        "      nearest_text = text_centers[0]\n",
        "      shortest_x = abs(face[0] - nearest_text[0])\n",
        "      shortest_y = abs(face[1] - nearest_text[1])\n",
        "      shortest_distance = math.sqrt(shortest_x**2 + shortest_y**2)\n",
        "\n",
        "      for text in text_centers:\n",
        "        distance_x = abs(face[0] - text[0])\n",
        "        distance_y = abs(face[1] - text[1])\n",
        "        distance = math.sqrt(distance_x**2 + distance_y**2)\n",
        "\n",
        "        if distance < shortest_distance:\n",
        "          shortest_distance = distance\n",
        "          nearest_text = text\n",
        "\n",
        "      face_to_text = [face, nearest_text]\n",
        "      faces_to_texts.append(face_to_text)\n",
        "  \n",
        "  for face_to_text in faces_to_texts:\n",
        "    face, text = face_to_text\n",
        "\n",
        "    face_x, face_y = face\n",
        "    text_x, text_y = text\n",
        "\n",
        "    length_x = abs(face_x - text_x)\n",
        "    length_y = abs(face_y - text_y)\n",
        "\n",
        "    if face_x > text_x: #face is to the right of text\n",
        "      length_x *= -1\n",
        "    if face_y > text_y: #face is below text\n",
        "      length_y *= -1\n",
        "\n",
        "    arrow = Arrow(face_x, face_y, length_x, length_y, color='cornflowerblue')\n",
        "    ax.add_patch(arrow)\n",
        "\n",
        "  pyplot.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "uNhxoCJ3wSvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dataset = test_set\n",
        "# dataset = train_set + test_set\n",
        "last_image_id = 0\n",
        "\n",
        "for book in sorted(p.books):\n",
        "  images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "  annotations_dir = root_dir + \"annotations/\" + book + \"/\"\n",
        "\n",
        "  for img in sorted(listdir(images_dir)):\n",
        "    image_id = int(img[:-4])\n",
        "    current_image_id = image_id + last_image_id\n",
        "\n",
        "    xml_file = annotations_dir + \"new_\" + book + str(image_id) + \".xml\"\n",
        "\n",
        "    tree = ElementTree.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    faces = []\n",
        "    texts = []\n",
        "\n",
        "    for face in root.findall(\".//face\"):\n",
        "      faces.append(face)\n",
        "    \n",
        "    for text in root.findall(\".//text\"):\n",
        "      texts.append(text)\n",
        "    \n",
        "    if len(faces) < 1: #if there are no faces\n",
        "      continue\n",
        "    \n",
        "    if len(texts) < 1: #if there are no texts\n",
        "      continue\n",
        "\n",
        "    arrow_face_text(dataset, current_image_id, cfg, model)\n",
        "\n",
        "    print(book, current_image_id)\n",
        "\n",
        "  last_image_id = current_image_id + 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "89CXAA7tmiMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Credits\n",
        "\n",
        "[Kangaroo](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/)\n",
        "\n",
        "[Matterport Mask RCNN](https://github.com/matterport/Mask_RCNN)\n",
        "\n",
        "[Manga109](http://www.manga109.org/en/index.html)"
      ],
      "metadata": {
        "id": "mtu7lTcqpV_9"
      }
    }
  ]
}