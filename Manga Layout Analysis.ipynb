{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Manga Layout Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPWiFXSXf_Mj"
      },
      "source": [
        "# About\n",
        "\n",
        "This research project for the 2021 Nanyang Research Programme (NRP) by Nanyang Technological University aims to segment character faces and speech bubbles of manga pages, associating each character face to the speech bubble of said character based on the distance between the two classes. In doing so, the project hopes to lay the foundation for easy translation and adaptation of manga into movie scripts, novels, and other literature pieces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvSDlr5yPqyU"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKJV3yaVMRhe"
      },
      "source": [
        "!pip3 uninstall keras-nightly\n",
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 install keras==2.1.6\n",
        "!pip3 install tensorflow==1.15.0\n",
        "!pip3 install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oztxkItMb67"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa61M3fOMhdS"
      },
      "source": [
        "%cd Mask_RCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNR9tCIWMmNf"
      },
      "source": [
        "!python setup.py install\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVw_z1VjO1nb"
      },
      "source": [
        "!pip install elementpath\n",
        "!pip install manga109api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq7ge8sqO2kB"
      },
      "source": [
        "import elementpath\n",
        "from xml.etree import ElementTree\n",
        "import manga109api\n",
        "from google.colab import files\n",
        "from os import listdir\n",
        "from numpy import zeros, asarray, expand_dims, mean\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset, extract_bboxes, compute_ap\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
        "import matplotlib.pyplot as pyplot\n",
        "from matplotlib.patches import Rectangle, Arrow\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jIldJh4T9fo"
      },
      "source": [
        "root_dir = \"/content/drive/MyDrive/NRP/Project/Manga109/\"\n",
        "p = manga109api.Parser(root_dir=root_dir)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i5QUXQDPboM"
      },
      "source": [
        "# Reformat Manga109 annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjmrNZ3GXLWx"
      },
      "source": [
        "%cd /content\n",
        "for book in p.books:\n",
        "  tree = ElementTree.parse(root_dir + \"annotations/\" + book + \".xml\")\n",
        "  root = tree.getroot()\n",
        "\n",
        "  %mkdir $book\n",
        "  %cd /content/$book\n",
        "\n",
        "  for page in root.findall('.//page'):\n",
        "    new_xml = page\n",
        "    b_xml = ElementTree.tostring(new_xml)\n",
        "    with open(\"new_\" + book + str(page.attrib[\"index\"]) + \".xml\", \"wb\") as f:\n",
        "      f.write(b_xml)\n",
        "  \n",
        "  %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g90nU93IYLqo"
      },
      "source": [
        "for book in p.books:\n",
        "  !zip -r /content/$book /content/$book"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qfL7lwheT6e"
      },
      "source": [
        "print('\\n'.join(p.books))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwQ9GyH4QKmI"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTO-V6wgDDET"
      },
      "source": [
        "class MangaDataset(Dataset):\n",
        "  def load_dataset(self, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"face\")\n",
        "    self.add_class(\"dataset\", 2, \"text\")\n",
        "    self.add_class(\"dataset\", 3, \"frame\")\n",
        "\n",
        "    last_image_id = 0\n",
        "\n",
        "    for book in sorted(p.books):\n",
        "      images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "      annotations_dir = root_dir + \"annotations/\" + book + \"/\"\n",
        "\n",
        "      for img in sorted(listdir(images_dir)):\n",
        "        og_image_id = int(img[:-4])\n",
        "        image_id = int(img[:-4]) + last_image_id\n",
        "      \n",
        "        tree = ElementTree.parse(annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\")\n",
        "        root = tree.getroot()\n",
        "        faces = []\n",
        "        texts = []\n",
        "        frames = []\n",
        "\n",
        "        for face in root.findall(\".//face\"):\n",
        "          faces.append(face)\n",
        "        \n",
        "        for text in root.findall(\".//text\"):\n",
        "          texts.append(text)\n",
        "        \n",
        "        for frame in root.findall(\".//frame\"):\n",
        "          frames.append(frame)\n",
        "        \n",
        "        if (not faces) or (not texts) or (not frames): #if there are no faces\n",
        "          continue\n",
        "\n",
        "        if is_train and og_image_id >= 50:\n",
        "          continue\n",
        "\n",
        "        if not is_train and og_image_id < 50:\n",
        "          continue\n",
        "        \n",
        "        img_path = images_dir + img\n",
        "        ann_path = annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\"\n",
        "\n",
        "        self.add_image(\"dataset\", image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0, 1, 2, 3])\n",
        "\n",
        "      last_image_id = image_id + 1\n",
        "\n",
        "\n",
        "  def extract_boxes(self, filename):\n",
        "    tree = ElementTree.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "\n",
        "    for box in root.findall(\".//face\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"face\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//text\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"text\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//frame\"):\n",
        "      att = box.attrib\n",
        "      xmin = att['xmin']\n",
        "      ymin = att['ymin']\n",
        "      xmax = att['xmax']\n",
        "      ymax = att['ymax']\n",
        "      coors = [xmin, ymin, xmax, ymax, \"frame\"]\n",
        "      boxes.append(coors)\n",
        "\n",
        "    page_att = root.attrib\n",
        "    width = int(page_att['width'])\n",
        "    height = int(page_att['height'])\n",
        "\n",
        "    return boxes, width, height\n",
        "\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    path = info[\"annotation\"]\n",
        "    boxes, w, h = self.extract_boxes(path)\n",
        "    \n",
        "    masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\n",
        "    class_ids = []\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "      box = boxes[i]\n",
        "      row_s, row_e = box[1], box[3]\n",
        "      col_s, col_e = box[0], box[2]\n",
        "\n",
        "      if box[4] == \"face\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 1\n",
        "        class_ids.append(self.class_names.index('face'))\n",
        "\n",
        "      elif box[4] == \"text\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 2\n",
        "        class_ids.append(self.class_names.index('text'))\n",
        "      \n",
        "      elif box[4] == \"frame\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 3\n",
        "        class_ids.append(self.class_names.index('frame'))\n",
        "\n",
        "    return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info[\"path\"]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQY5a2ZtVZd0"
      },
      "source": [
        "# train set\n",
        "train_set = MangaDataset()\n",
        "train_set.load_dataset(is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        " \n",
        "# test/val set\n",
        "test_set = MangaDataset()\n",
        "test_set.load_dataset(is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_0BF1ZhHvro"
      },
      "source": [
        "# load an image and mask\n",
        "image_id = 1\n",
        "image = train_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "print(mask.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9LK6YXgA4A"
      },
      "source": [
        "# display image with masks and bounding boxes\n",
        "bbox = extract_bboxes(mask)\n",
        "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kxl7xZvfVRf"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iCDgc7KfYpw"
      },
      "source": [
        "class MangaConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  STEPS_PER_EPOCH = 131"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMDpJv8dgCfv"
      },
      "source": [
        "config = MangaConfig()\n",
        "model = MaskRCNN(mode='training', model_dir='/content', config=config)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/NRP/Project/Working/model_5.h5',\n",
        "                   by_name=True,\n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_set, test_set, learning_rate=0.000001, epochs=40, layers=\"all\")\n",
        "\n",
        "# config.LEARNING_RATE = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_esT8GtjQnpU"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKR7ueWM41Yj"
      },
      "source": [
        "class PredictionConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGwpuPD045Gw"
      },
      "source": [
        "cfg = PredictionConfig()\n",
        "model = MaskRCNN(mode='inference', model_dir='/content', config=cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35C0dWQC4-bR"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/NRP/Project/Working/model_5.h5', by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e2b_whw5Rqj"
      },
      "source": [
        "def evaluate_model(dataset, model, cfg):\n",
        "  APs = []\n",
        "  for image_id in dataset.image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "    scaled_image = mold_image(image, cfg)\n",
        "    sample = expand_dims(scaled_image, 0)\n",
        "    yhat = model.detect(sample, verbose=0)\n",
        "    r = yhat[0]\n",
        "\n",
        "    AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "\n",
        "  mAP = mean(APs)\n",
        "  return mAP"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3fmfY2Q5VFh"
      },
      "source": [
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "\n",
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji8U486_kHF7"
      },
      "source": [
        "# Associate Face to Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNhxoCJ3wSvP"
      },
      "source": [
        "def arrow_face_text(dataset, image_id, cfg, model):\n",
        "  image = dataset.load_image(image_id)\n",
        "  mask, _ = dataset.load_mask(image_id)\n",
        "  scaled_image = mold_image(image, cfg)\n",
        "  sample = expand_dims(scaled_image, 0)\n",
        "\n",
        "  yhat = model.detect(sample, verbose=0)[0]\n",
        "  rois = list(yhat['rois'])\n",
        "  class_ids = list(yhat['class_ids'])\n",
        "\n",
        "  for j in range(mask.shape[2]):\n",
        "    pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "  \n",
        "  pyplot.subplot(111)\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title('Face to Text')\n",
        "\n",
        "  ax = pyplot.gca()\n",
        "\n",
        "  face_centers = []\n",
        "  text_centers = []\n",
        "  frame_corners = []\n",
        "  count = 0\n",
        "\n",
        "  for id in class_ids:\n",
        "    box = rois[count]\n",
        "    count += 1\n",
        "\n",
        "    y1, x1, y2, x2 = box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "\n",
        "    rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    if id == 1:\n",
        "      face_x = (x1 + x2)//2\n",
        "      face_y = (y1 + y2)//2\n",
        "      face_center = [face_x, face_y]\n",
        "      face_centers.append(face_center)\n",
        "    elif id == 2:\n",
        "      text_x = (x1 + x2)//2\n",
        "      text_y = (y1 + y2)//2\n",
        "      text_center = [text_x, text_y]\n",
        "      text_centers.append(text_center)\n",
        "    elif id == 3:\n",
        "      frame_corners.append([x1, x2, y1, y2])\n",
        "\n",
        "  faces_to_texts = []\n",
        "\n",
        "  for frame in frame_corners:\n",
        "    x1, x2, y1, y2 = frame\n",
        "    face_centers_filtered, text_centers_filtered = [], []\n",
        "    num_faces, num_text = 0, 0\n",
        "\n",
        "    for face in face_centers:\n",
        "      if face[0] < x2 and face[0] > x1 and face[1] < y2 and face[1] > y1:\n",
        "        num_faces += 1\n",
        "        face_centers_filtered.append(face)\n",
        "    for text in text_centers:\n",
        "      if text[0] < x2 and text[0] > x1 and text[1] < y2 and text[1] > y1:\n",
        "        num_text += 1\n",
        "        text_centers_filtered.append(text)\n",
        "    \n",
        "    if num_faces >= num_text:\n",
        "      for face in face_centers_filtered:\n",
        "        if text_centers_filtered:\n",
        "          nearest_text = text_centers_filtered[0]\n",
        "          shortest_x = abs(face[0] - nearest_text[0])\n",
        "          shortest_y = abs(face[1] - nearest_text[1])\n",
        "          shortest_distance = math.sqrt(shortest_x**2 + shortest_y**2)\n",
        "\n",
        "          for text in text_centers_filtered:\n",
        "            distance_x = abs(face[0] - text[0])\n",
        "            distance_y = abs(face[1] - text[1])\n",
        "            distance = math.sqrt(distance_x**2 + distance_y**2)\n",
        "\n",
        "            if distance < shortest_distance:\n",
        "              shortest_distance = distance\n",
        "              nearest_text = text\n",
        "\n",
        "          face_to_text = [face, nearest_text]\n",
        "          faces_to_texts.append(face_to_text)\n",
        "\n",
        "    elif num_faces < num_text:\n",
        "      for text in text_centers_filtered:\n",
        "        if face_centers_filtered:\n",
        "          nearest_face = face_centers_filtered[0]\n",
        "          shortest_x = abs(text[0] - nearest_face[0])\n",
        "          shortest_y = abs(text[1] - nearest_face[1])\n",
        "          shortest_distance = math.sqrt(shortest_x**2 + shortest_y**2)\n",
        "\n",
        "          for face in face_centers_filtered:\n",
        "            distance_x = abs(face[0] - text[0])\n",
        "            distance_y = abs(face[1] - text[1])\n",
        "            distance = math.sqrt(distance_x**2 + distance_y**2)\n",
        "\n",
        "            if distance < shortest_distance:\n",
        "              shortest_distance = distance\n",
        "              nearest_face = face\n",
        "\n",
        "          face_to_text = [nearest_face, text]\n",
        "          faces_to_texts.append(face_to_text)\n",
        "\n",
        "  for face_to_text in faces_to_texts:\n",
        "    face, text = face_to_text\n",
        "\n",
        "    face_x, face_y = face\n",
        "    text_x, text_y = text\n",
        "\n",
        "    length_x = abs(face_x - text_x)\n",
        "    length_y = abs(face_y - text_y)\n",
        "\n",
        "    if face_x > text_x: #face is to the right of text\n",
        "      length_x *= -1\n",
        "    if face_y > text_y: #face is below text\n",
        "      length_y *= -1\n",
        "\n",
        "    arrow = Arrow(face_x, face_y, length_x, length_y, color='cornflowerblue')\n",
        "    ax.add_patch(arrow)\n",
        "\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89CXAA7tmiMa"
      },
      "source": [
        "dataset = test_set\n",
        "# dataset = train_set + test_set\n",
        "last_image_id = 0\n",
        "\n",
        "for book in sorted(p.books):\n",
        "  images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "  annotations_dir = root_dir + \"annotations/\" + book + \"/\"\n",
        "\n",
        "  for img in sorted(listdir(images_dir)):\n",
        "    image_id = int(img[:-4])\n",
        "    current_image_id = image_id + last_image_id\n",
        "\n",
        "    xml_file = annotations_dir + \"new_\" + book + str(image_id) + \".xml\"\n",
        "\n",
        "    tree = ElementTree.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    faces = []\n",
        "    texts = []\n",
        "\n",
        "    for face in root.findall(\".//face\"):\n",
        "      faces.append(face)\n",
        "    \n",
        "    for text in root.findall(\".//text\"):\n",
        "      texts.append(text)\n",
        "    \n",
        "    if len(faces) < 1: #if there are no faces\n",
        "      continue\n",
        "    \n",
        "    if len(texts) < 1: #if there are no texts\n",
        "      continue\n",
        "\n",
        "    arrow_face_text(dataset, current_image_id, cfg, model)\n",
        "\n",
        "    print(book, current_image_id)\n",
        "\n",
        "  last_image_id = current_image_id + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtu7lTcqpV_9"
      },
      "source": [
        "# Credits\n",
        "\n",
        "[Kangaroo](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/)\n",
        "\n",
        "[Matterport Mask RCNN](https://github.com/matterport/Mask_RCNN)\n",
        "\n",
        "[Manga109](http://www.manga109.org/en/index.html)"
      ]
    }
  ]
}