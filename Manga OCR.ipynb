{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Manga OCR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT3bPfHpjeM_"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Train in [Kaggle](https://www.kaggle.com/xyntechx/manga-ocr/edit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFZrbdrNJwBt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i8g2x0uEriy"
      },
      "source": [
        "!git clone https://github.com/rois-codh/kmnist.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB46iFSWHcOW"
      },
      "source": [
        "%cd kmnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD7H4yV3HXkn"
      },
      "source": [
        "# Download Kuzushiji-49\n",
        "!python download_data.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v8b7qhYjrAG"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import imutils\n",
        "from imutils import build_montages\n",
        "from imutils.contours import sort_contours\n",
        "import cv2\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNFDnRjr8jyr"
      },
      "source": [
        "%cd /content/drive/MyDrive/NRP/Project/OCRData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTWyKIsvmCYT"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loOLK4GXO_-U"
      },
      "source": [
        "def load_hiragana_dataset():\n",
        "    TRAIN_DATA = \"/content/kmnist/k49-train-imgs.npz\"\n",
        "    TRAIN_LABELS = \"/content/kmnist/k49-train-labels.npz\"\n",
        "    TEST_DATA = \"/content/kmnist/k49-test-imgs.npz\"\n",
        "    TEST_LABELS = \"/content/kmnist/k49-test-labels.npz\"\n",
        "\n",
        "    train_data = np.load(TRAIN_DATA)[\"arr_0\"]\n",
        "    train_labels = np.load(TRAIN_LABELS)[\"arr_0\"]\n",
        "    test_data = np.load(TEST_DATA)[\"arr_0\"]\n",
        "    test_labels = np.load(TEST_LABELS)[\"arr_0\"]\n",
        "\n",
        "    data = np.vstack([train_data, test_data])\n",
        "    data = [cv2.resize(image, (32, 32)) for image in data]\n",
        "    data = np.array(data, dtype=\"float32\")\n",
        "    data = np.expand_dims(data, axis=-1)\n",
        "    data /= 255.0\n",
        "\n",
        "    labels = np.hstack([train_labels, test_labels])\n",
        "\n",
        "    return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDF-cCd0r-8"
      },
      "source": [
        "def load_kanji_dataset():\n",
        "    TRAIN_DATA = \"/content/drive/MyDrive/NRP/Project/OCRData/kuzushiji50_train_imgs.npy\"\n",
        "    TRAIN_LABELS = \"/content/drive/MyDrive/NRP/Project/OCRData/kuzushiji50_train_labels.npy\"\n",
        "    TEST_DATA = \"/content/drive/MyDrive/NRP/Project/OCRData/kuzushiji50_test_imgs.npy\"\n",
        "    TEST_LABELS = \"/content/drive/MyDrive/NRP/Project/OCRData/kuzushiji50_test_labels.npy\"\n",
        "\n",
        "    train_data = np.load(TRAIN_DATA)\n",
        "    train_labels = np.load(TRAIN_LABELS)\n",
        "    test_data = np.load(TEST_DATA)\n",
        "    test_labels = np.load(TEST_LABELS)\n",
        "\n",
        "    data = np.vstack([train_data, test_data])\n",
        "    data = [cv2.resize(image, (32, 32)) for image in data]\n",
        "    data = np.array(data, dtype=\"float32\")\n",
        "    data = np.expand_dims(data, axis=-1)\n",
        "    data /= 255.0\n",
        "\n",
        "    labels = np.hstack([train_labels, test_labels])\n",
        "    labels = [i+49 for i in labels]\n",
        "    labels = np.array(labels, dtype=\"int\")\n",
        "\n",
        "    return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8dnkfFbnC3p"
      },
      "source": [
        "data_hiragana, labels_hiragana = load_hiragana_dataset()\n",
        "data_kanji, labels_kanji = load_kanji_dataset()\n",
        "\n",
        "data = np.vstack([data_hiragana, data_kanji])\n",
        "labels = np.hstack([labels_hiragana, labels_kanji])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NL-NhCmtU1i"
      },
      "source": [
        "le = LabelBinarizer()\n",
        "labels = le.fit_transform(labels)\n",
        "counts = labels.sum(axis=0)\n",
        "\n",
        "class_totals = labels.sum(axis=0)\n",
        "class_weight = {}\n",
        "\n",
        "for i in range(0, len(class_totals)):\n",
        "    class_weight[i] = class_totals.max() / class_totals[i]\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQVAZ59tpA_"
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.05,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AugiSlTnuRqH"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah4zVTnjm5oD"
      },
      "source": [
        "# Settings\n",
        "EPOCHS = 50\n",
        "INIT_LR = 1e-1\n",
        "BS = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVEBgWEizTyp"
      },
      "source": [
        "model = tf.keras.applications.resnet50.ResNet50(input_shape=(32, 32, 1), weights=None, classes=99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfjKm5hauNaH"
      },
      "source": [
        "opt = SGD(learning_rate=INIT_LR, decay=INIT_LR/EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvwhUV9ww7-J"
      },
      "source": [
        "H = model.fit(\n",
        "    aug.flow(train_x, train_y, batch_size=BS),\n",
        "    validation_data=(test_x, test_y),\n",
        "    steps_per_epoch=len(train_x)//BS,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weight,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6cw7bV96Ed"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdITzk3uG-gc"
      },
      "source": [
        "model.save(\"manga_ocr.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmKe8zg8J6ik"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n11UDImJ5kr"
      },
      "source": [
        "model = tf.keras.applications.resnet50.ResNet50(input_shape=(32, 32, 1), weights=None, classes=99)\n",
        "model.load_weights(\"/content/drive/MyDrive/NRP/Project/Working/OCR/kanji_hiragana.h5\")\n",
        "label_names = [str(index) for index in range(99)]\n",
        "predictions = model.predict(test_x, batch_size=BS)\n",
        "\n",
        "print(classification_report(test_y.argmax(axis=1), predictions.argmax(axis=1), target_names=label_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w-oqsz3J_Zb"
      },
      "source": [
        "# Analyse Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aMYxugOGBNz"
      },
      "source": [
        "images = []\n",
        "\n",
        "for i in np.random.choice(np.arange(0, len(test_y)), size=(49,)):\n",
        "    probs = model.predict(test_x[np.newaxis, i])\n",
        "    prediction = probs.argmax(axis=1)\n",
        "    label = label_names[prediction[0]]\n",
        "    image = (test_x[i]*255).astype(\"uint8\")\n",
        "    color = (0, 255, 0)\n",
        "\n",
        "    if prediction[0] != np.argmax(test_y[i]):\n",
        "        color = (0, 0, 255)\n",
        "\n",
        "    image = cv2.merge([image] * 3)\n",
        "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "    cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n",
        "    images.append(image)\n",
        "\n",
        "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
        "\n",
        "cv2_imshow(montage)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKwk-Y57VqwU"
      },
      "source": [
        "# Use Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dph09b6yWOQ1"
      },
      "source": [
        "image = cv2.imread(\"/content/sample.png\")\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "edged = cv2.Canny(blurred, 30, 150)\n",
        "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
        "\n",
        "chars = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M2W9UI3a8qd"
      },
      "source": [
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUdRpxkcXjAq"
      },
      "source": [
        "for c in cnts:\n",
        "\t(x, y, w, h) = cv2.boundingRect(c)\n",
        " \n",
        "\tif (w >= 5 and w <= 150) and (h >= 15 and h <= 120):\n",
        "\t\troi = gray[y:y + h, x:x + w]\n",
        "\t\tthresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\n",
        "\t\tif tW > tH:\n",
        "\t\t\tthresh = imutils.resize(thresh, width=32)\n",
        "\t\telse:\n",
        "\t\t\tthresh = imutils.resize(thresh, height=32)\n",
        "   \n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
        "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
        "  \n",
        "\t\tpadded = cv2.copyMakeBorder(\n",
        "              thresh,\n",
        "              top=dY,\n",
        "              bottom=dY,\n",
        "              left=dX,\n",
        "              right=dX,\n",
        "              borderType=cv2.BORDER_CONSTANT,\n",
        "              value=(0, 0, 0)\n",
        "        )\n",
        "  \n",
        "\t\tpadded = cv2.resize(padded, (32, 32))\n",
        "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
        "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
        "  \n",
        "\t\tchars.append((padded, (x, y, w, h)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Q7hVQmYEE7"
      },
      "source": [
        "model = tf.keras.applications.resnet50.ResNet50(input_shape=(32, 32, 1), weights=None, classes=99)\n",
        "model.load_weights(\"/content/drive/MyDrive/NRP/Project/Working/kanji_hiragana.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loaCk3ZIX218"
      },
      "source": [
        "boxes = [b[1] for b in chars]\n",
        "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
        "preds = model.predict(chars)\n",
        "label_names = [str(index) for index in range(99)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYq2jON4YCZo"
      },
      "source": [
        "for pred, (x, y, w, h) in zip(preds, boxes):\n",
        "\ti = np.argmax(pred)\n",
        "\tprob = pred[i]\n",
        "\tlabel = label_names[i]\n",
        "\n",
        "\tprint(\"Label:\", label, \"\\tProbability:\", prob * 100)\n",
        "\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\tcv2.putText(image, label, (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}