{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvSDlr5yPqyU"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnxJIeHIq5Nc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKJV3yaVMRhe"
      },
      "outputs": [],
      "source": [
        "!pip3 uninstall keras-nightly\n",
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 install keras==2.1.6\n",
        "!pip3 install tensorflow==1.15.0\n",
        "!pip3 install h5py==2.10.0\n",
        "!pip3 install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oztxkItMb67"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa61M3fOMhdS"
      },
      "outputs": [],
      "source": [
        "%cd Mask_RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNR9tCIWMmNf"
      },
      "outputs": [],
      "source": [
        "!python setup.py install\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVw_z1VjO1nb"
      },
      "outputs": [],
      "source": [
        "!pip install elementpath\n",
        "!pip install manga109api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq7ge8sqO2kB"
      },
      "outputs": [],
      "source": [
        "import elementpath\n",
        "from xml.etree import ElementTree\n",
        "import manga109api\n",
        "from google.colab import files\n",
        "from os import listdir\n",
        "from numpy import zeros, asarray, expand_dims, mean\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset, extract_bboxes, compute_ap\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
        "import matplotlib.pyplot as pyplot\n",
        "from matplotlib.patches import Rectangle, Arrow\n",
        "import math\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jIldJh4T9fo"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/NRP/Project/Manga109/\"\n",
        "p = manga109api.Parser(root_dir=root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i5QUXQDPboM"
      },
      "source": [
        "# Reformat Manga109 annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHEqtgCkeNgE"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjmrNZ3GXLWx"
      },
      "outputs": [],
      "source": [
        "for book in p.books:\n",
        "  tree = ElementTree.parse(root_dir + \"annotations/\" + book + \".xml\")\n",
        "  root = tree.getroot()\n",
        "\n",
        "  %mkdir $book\n",
        "  %cd /content/$book\n",
        "\n",
        "  for page in root.findall(\".//page\"):\n",
        "    new_xml = page\n",
        "    b_xml = ElementTree.tostring(new_xml)\n",
        "    with open(\"new_\" + book + str(page.attrib[\"index\"]) + \".xml\", \"wb\") as f:\n",
        "      f.write(b_xml)\n",
        "  \n",
        "  %cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g90nU93IYLqo"
      },
      "outputs": [],
      "source": [
        "for book in p.books:\n",
        "  !zip -r /content/$book /content/$book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qfL7lwheT6e"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\".join(p.books))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwQ9GyH4QKmI"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTO-V6wgDDET"
      },
      "outputs": [],
      "source": [
        "class MangaDataset(Dataset):\n",
        "  def load_dataset(self, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"face\")\n",
        "    self.add_class(\"dataset\", 2, \"text\")\n",
        "    self.add_class(\"dataset\", 3, \"frame\")\n",
        "\n",
        "    last_image_id = 0\n",
        "\n",
        "    for book in sorted(p.books):\n",
        "      images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "      annotations_dir = root_dir + \"annotations/\" + book + \"/\"\n",
        "\n",
        "      for img in sorted(listdir(images_dir)):\n",
        "        og_image_id = int(img[:-4])\n",
        "        image_id = int(img[:-4]) + last_image_id\n",
        "      \n",
        "        tree = ElementTree.parse(annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\")\n",
        "        root = tree.getroot()\n",
        "        faces = []\n",
        "        texts = []\n",
        "        frames = []\n",
        "\n",
        "        for face in root.findall(\".//face\"):\n",
        "          faces.append(face)\n",
        "        \n",
        "        for text in root.findall(\".//text\"):\n",
        "          texts.append(text)\n",
        "        \n",
        "        for frame in root.findall(\".//frame\"):\n",
        "          frames.append(frame)\n",
        "        \n",
        "        if (not faces) or (not texts) or (not frames):\n",
        "          continue\n",
        "\n",
        "        if is_train and og_image_id >= 50:\n",
        "          continue\n",
        "\n",
        "        if not is_train and og_image_id < 50:\n",
        "          continue\n",
        "        \n",
        "        img_path = images_dir + img\n",
        "        ann_path = annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\"\n",
        "\n",
        "        self.add_image(\"dataset\", image_id=image_id, path=img_path, annotation=ann_path, class_ids=[0, 1, 2, 3])\n",
        "\n",
        "      last_image_id = image_id + 1\n",
        "\n",
        "\n",
        "  def extract_boxes(self, filename):\n",
        "    tree = ElementTree.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "\n",
        "    for box in root.findall(\".//face\"):\n",
        "      att = box.attrib\n",
        "      xmin = att[\"xmin\"]\n",
        "      ymin = att[\"ymin\"]\n",
        "      xmax = att[\"xmax\"]\n",
        "      ymax = att[\"ymax\"]\n",
        "      coors = [xmin, ymin, xmax, ymax, \"face\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//text\"):\n",
        "      att = box.attrib\n",
        "      xmin = att[\"xmin\"]\n",
        "      ymin = att[\"ymin\"]\n",
        "      xmax = att[\"xmax\"]\n",
        "      ymax = att[\"ymax\"]\n",
        "      coors = [xmin, ymin, xmax, ymax, \"text\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//frame\"):\n",
        "      att = box.attrib\n",
        "      xmin = att[\"xmin\"]\n",
        "      ymin = att[\"ymin\"]\n",
        "      xmax = att[\"xmax\"]\n",
        "      ymax = att[\"ymax\"]\n",
        "      coors = [xmin, ymin, xmax, ymax, \"frame\"]\n",
        "      boxes.append(coors)\n",
        "\n",
        "    page_att = root.attrib\n",
        "    width = int(page_att[\"width\"])\n",
        "    height = int(page_att[\"height\"])\n",
        "\n",
        "    return boxes, width, height\n",
        "\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    path = info[\"annotation\"]\n",
        "    boxes, w, h = self.extract_boxes(path)\n",
        "    \n",
        "    masks = zeros([h, w, len(boxes)], dtype=\"uint8\")\n",
        "\n",
        "    class_ids = []\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "      box = boxes[i]\n",
        "      row_s, row_e = box[1], box[3]\n",
        "      col_s, col_e = box[0], box[2]\n",
        "\n",
        "      if box[4] == \"face\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 1\n",
        "        class_ids.append(self.class_names.index(\"face\"))\n",
        "\n",
        "      elif box[4] == \"text\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 2\n",
        "        class_ids.append(self.class_names.index(\"text\"))\n",
        "      \n",
        "      elif box[4] == \"frame\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 3\n",
        "        class_ids.append(self.class_names.index(\"frame\"))\n",
        "\n",
        "    return masks, asarray(class_ids, dtype=\"int32\")\n",
        "\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info[\"path\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQY5a2ZtVZd0"
      },
      "outputs": [],
      "source": [
        "# train set\n",
        "train_set = MangaDataset()\n",
        "train_set.load_dataset(is_train=True)\n",
        "train_set.prepare()\n",
        "print(\"Train: %d\" % len(train_set.image_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6aq6AhoXPdg"
      },
      "outputs": [],
      "source": [
        "# test/val set\n",
        "test_set = MangaDataset()\n",
        "test_set.load_dataset(is_train=False)\n",
        "test_set.prepare()\n",
        "print(\"Test: %d\" % len(test_set.image_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_0BF1ZhHvro"
      },
      "outputs": [],
      "source": [
        "# load an image and mask\n",
        "image_id = 1\n",
        "image = test_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "\n",
        "mask, class_ids = test_set.load_mask(image_id)\n",
        "print(mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf9LK6YXgA4A"
      },
      "outputs": [],
      "source": [
        "# display image with masks and bounding boxes\n",
        "bbox = extract_bboxes(mask)\n",
        "display_instances(image, bbox, mask, class_ids, test_set.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kxl7xZvfVRf"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iCDgc7KfYpw"
      },
      "outputs": [],
      "source": [
        "class MangaConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  STEPS_PER_EPOCH = len(train_set.image_ids) // 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = MangaConfig()"
      ],
      "metadata": {
        "id": "RkzgtuvVL3bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MaskRCNN(mode=\"training\", model_dir=\"/content\", config=config)\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/NRP/Project/Working/Mask R-CNN (3)/model_3.h5\",\n",
        "                   by_name=True,\n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=1, layers=\"all\")\n",
        "\n",
        "# config.LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "DDiDkQzoRklk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_esT8GtjQnpU"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKR7ueWM41Yj"
      },
      "outputs": [],
      "source": [
        "class PredictionConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGwpuPD045Gw"
      },
      "outputs": [],
      "source": [
        "cfg = PredictionConfig()\n",
        "model = MaskRCNN(mode=\"inference\", model_dir=\"/content\", config=cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35C0dWQC4-bR"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/NRP/Project/Working/Mask R-CNN (3)/model_4.h5\", by_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e2b_whw5Rqj"
      },
      "outputs": [],
      "source": [
        "# evaluate model using Manga109 dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "  APs = []\n",
        "  for image_id in dataset.image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "    scaled_image = mold_image(image, cfg)\n",
        "    sample = expand_dims(scaled_image, 0)\n",
        "    yhat = model.detect(sample, verbose=0)\n",
        "    r = yhat[0]\n",
        "\n",
        "    # change IoU threshold\n",
        "    AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r[\"masks\"], iou_threshold=0.5)\n",
        "    APs.append(AP)\n",
        "\n",
        "  mAP = mean(APs)\n",
        "  return mAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3fmfY2Q5VFh"
      },
      "outputs": [],
      "source": [
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eKuea8uootr"
      },
      "outputs": [],
      "source": [
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IS[Mask R-CNN].ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}