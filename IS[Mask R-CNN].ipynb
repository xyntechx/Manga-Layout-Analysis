{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IS[Mask R-CNN].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvSDlr5yPqyU"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnxJIeHIq5Nc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKJV3yaVMRhe"
      },
      "source": [
        "!pip3 uninstall keras-nightly\n",
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 install keras==2.1.6\n",
        "!pip3 install tensorflow==1.15.0\n",
        "!pip3 install h5py==2.10.0\n",
        "!pip3 install opencv-contrib-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oztxkItMb67"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa61M3fOMhdS"
      },
      "source": [
        "%cd Mask_RCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNR9tCIWMmNf"
      },
      "source": [
        "!python setup.py install\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVw_z1VjO1nb"
      },
      "source": [
        "!pip install elementpath\n",
        "!pip install manga109api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq7ge8sqO2kB"
      },
      "source": [
        "import elementpath\n",
        "from xml.etree import ElementTree\n",
        "import manga109api\n",
        "from google.colab import files\n",
        "from os import listdir\n",
        "from numpy import zeros, asarray, expand_dims, mean\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset, extract_bboxes, compute_ap\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
        "import matplotlib.pyplot as pyplot\n",
        "from matplotlib.patches import Rectangle, Arrow\n",
        "import math\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jIldJh4T9fo"
      },
      "source": [
        "root_dir = \"/content/drive/MyDrive/NRP/Project/Manga109/\"\n",
        "p = manga109api.Parser(root_dir=root_dir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i5QUXQDPboM"
      },
      "source": [
        "# Reformat Manga109 annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHEqtgCkeNgE"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjmrNZ3GXLWx"
      },
      "source": [
        "for book in p.books:\n",
        "  tree = ElementTree.parse(root_dir + \"annotations/\" + book + \".xml\")\n",
        "  root = tree.getroot()\n",
        "\n",
        "  %mkdir $book\n",
        "  %cd /content/$book\n",
        "\n",
        "  for page in root.findall(\".//page\"):\n",
        "    new_xml = page\n",
        "    b_xml = ElementTree.tostring(new_xml)\n",
        "    with open(\"new_\" + book + str(page.attrib[\"index\"]) + \".xml\", \"wb\") as f:\n",
        "      f.write(b_xml)\n",
        "  \n",
        "  %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g90nU93IYLqo"
      },
      "source": [
        "for book in p.books:\n",
        "  !zip -r /content/$book /content/$book"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qfL7lwheT6e"
      },
      "source": [
        "print(\"\\n\".join(p.books))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwQ9GyH4QKmI"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTO-V6wgDDET"
      },
      "source": [
        "class MangaDataset(Dataset):\n",
        "  def load_dataset(self, is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"face\")\n",
        "    self.add_class(\"dataset\", 2, \"text\")\n",
        "    self.add_class(\"dataset\", 3, \"frame\")\n",
        "\n",
        "    last_image_id = 0\n",
        "\n",
        "    for book in sorted(p.books):\n",
        "      images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "      annotations_dir = root_dir + \"annotations/\" + book + \"/\"\n",
        "\n",
        "      for img in sorted(listdir(images_dir)):\n",
        "        og_image_id = int(img[:-4])\n",
        "        image_id = int(img[:-4]) + last_image_id\n",
        "      \n",
        "        tree = ElementTree.parse(annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\")\n",
        "        root = tree.getroot()\n",
        "        faces = []\n",
        "        texts = []\n",
        "        frames = []\n",
        "\n",
        "        for face in root.findall(\".//face\"):\n",
        "          faces.append(face)\n",
        "        \n",
        "        for text in root.findall(\".//text\"):\n",
        "          texts.append(text)\n",
        "        \n",
        "        for frame in root.findall(\".//frame\"):\n",
        "          frames.append(frame)\n",
        "        \n",
        "        if (not faces) or (not texts) or (not frames):\n",
        "          continue\n",
        "\n",
        "        if is_train and og_image_id >= 50:\n",
        "          continue\n",
        "\n",
        "        if not is_train and og_image_id < 50:\n",
        "          continue\n",
        "        \n",
        "        img_path = images_dir + img\n",
        "        ann_path = annotations_dir + \"new_\" + book + str(og_image_id) + \".xml\"\n",
        "\n",
        "        self.add_image(\"dataset\", image_id=image_id, path=img_path, annotation=ann_path, class_ids=[0, 1, 2, 3])\n",
        "\n",
        "      last_image_id = image_id + 1\n",
        "\n",
        "\n",
        "  def extract_boxes(self, filename):\n",
        "    tree = ElementTree.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "\n",
        "    for box in root.findall(\".//face\"):\n",
        "      att = box.attrib\n",
        "      xmin = att[\"xmin\"]\n",
        "      ymin = att[\"ymin\"]\n",
        "      xmax = att[\"xmax\"]\n",
        "      ymax = att[\"ymax\"]\n",
        "      coors = [xmin, ymin, xmax, ymax, \"face\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//text\"):\n",
        "      att = box.attrib\n",
        "      xmin = att[\"xmin\"]\n",
        "      ymin = att[\"ymin\"]\n",
        "      xmax = att[\"xmax\"]\n",
        "      ymax = att[\"ymax\"]\n",
        "      coors = [xmin, ymin, xmax, ymax, \"text\"]\n",
        "      boxes.append(coors)\n",
        "    \n",
        "    for box in root.findall(\".//frame\"):\n",
        "      att = box.attrib\n",
        "      xmin = att[\"xmin\"]\n",
        "      ymin = att[\"ymin\"]\n",
        "      xmax = att[\"xmax\"]\n",
        "      ymax = att[\"ymax\"]\n",
        "      coors = [xmin, ymin, xmax, ymax, \"frame\"]\n",
        "      boxes.append(coors)\n",
        "\n",
        "    page_att = root.attrib\n",
        "    width = int(page_att[\"width\"])\n",
        "    height = int(page_att[\"height\"])\n",
        "\n",
        "    return boxes, width, height\n",
        "\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    path = info[\"annotation\"]\n",
        "    boxes, w, h = self.extract_boxes(path)\n",
        "    \n",
        "    masks = zeros([h, w, len(boxes)], dtype=\"uint8\")\n",
        "\n",
        "    class_ids = []\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "      box = boxes[i]\n",
        "      row_s, row_e = box[1], box[3]\n",
        "      col_s, col_e = box[0], box[2]\n",
        "\n",
        "      if box[4] == \"face\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 1\n",
        "        class_ids.append(self.class_names.index(\"face\"))\n",
        "\n",
        "      elif box[4] == \"text\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 2\n",
        "        class_ids.append(self.class_names.index(\"text\"))\n",
        "      \n",
        "      elif box[4] == \"frame\":\n",
        "        masks[int(row_s):int(row_e), int(col_s):int(col_e), i] = 3\n",
        "        class_ids.append(self.class_names.index(\"frame\"))\n",
        "\n",
        "    return masks, asarray(class_ids, dtype=\"int32\")\n",
        "\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info[\"path\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQY5a2ZtVZd0"
      },
      "source": [
        "# train set\n",
        "train_set = MangaDataset()\n",
        "train_set.load_dataset(is_train=True)\n",
        "train_set.prepare()\n",
        "print(\"Train: %d\" % len(train_set.image_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test/val set\n",
        "test_set = MangaDataset()\n",
        "test_set.load_dataset(is_train=False)\n",
        "test_set.prepare()\n",
        "print(\"Test: %d\" % len(test_set.image_ids))"
      ],
      "metadata": {
        "id": "n6aq6AhoXPdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_0BF1ZhHvro"
      },
      "source": [
        "# load an image and mask\n",
        "image_id = 1\n",
        "image = test_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "\n",
        "mask, class_ids = test_set.load_mask(image_id)\n",
        "print(mask.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9LK6YXgA4A"
      },
      "source": [
        "# display image with masks and bounding boxes\n",
        "bbox = extract_bboxes(mask)\n",
        "display_instances(image, bbox, mask, class_ids, test_set.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kxl7xZvfVRf"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iCDgc7KfYpw"
      },
      "source": [
        "class MangaConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  STEPS_PER_EPOCH = 131"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMDpJv8dgCfv"
      },
      "source": [
        "config = MangaConfig()\n",
        "model = MaskRCNN(mode=\"training\", model_dir=\"/content\", config=config)\n",
        "\n",
        "model.load_weights(\"/content/drive/MyDrive/NRP/Project/Working/model_6.h5\",\n",
        "                   by_name=True,\n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_set, test_set, learning_rate=0.000005, epochs=40, layers=\"all\")\n",
        "\n",
        "# config.LEARNING_RATE = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_esT8GtjQnpU"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKR7ueWM41Yj"
      },
      "source": [
        "class PredictionConfig(Config):\n",
        "  NAME = \"manga_cfg\"\n",
        "  NUM_CLASSES = 1 + 3\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGwpuPD045Gw"
      },
      "source": [
        "cfg = PredictionConfig()\n",
        "model = MaskRCNN(mode=\"inference\", model_dir=\"/content\", config=cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35C0dWQC4-bR"
      },
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/NRP/Project/Working/model_5.h5\", by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e2b_whw5Rqj"
      },
      "source": [
        "# evaluate model using Manga109 dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "  APs = []\n",
        "  for image_id in dataset.image_ids:\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "    scaled_image = mold_image(image, cfg)\n",
        "    sample = expand_dims(scaled_image, 0)\n",
        "    yhat = model.detect(sample, verbose=0)\n",
        "    r = yhat[0]\n",
        "\n",
        "    # change IoU threshold\n",
        "    AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r[\"masks\"], iou_threshold=0.5)\n",
        "    APs.append(AP)\n",
        "\n",
        "  mAP = mean(APs)\n",
        "  return mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3fmfY2Q5VFh"
      },
      "source": [
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "metadata": {
        "id": "2eKuea8uootr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji8U486_kHF7"
      },
      "source": [
        "# Face-Text Association"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNhxoCJ3wSvP"
      },
      "source": [
        "def arrow_face_text(dataset, image_id, cfg, model):\n",
        "  image = dataset.load_image(image_id)\n",
        "  mask, _ = dataset.load_mask(image_id)\n",
        "  scaled_image = mold_image(image, cfg)\n",
        "  sample = expand_dims(scaled_image, 0)\n",
        "\n",
        "  yhat = model.detect(sample, verbose=0)[0]\n",
        "  rois = list(yhat[\"rois\"])\n",
        "  class_ids = list(yhat[\"class_ids\"])\n",
        "\n",
        "  for j in range(mask.shape[2]):\n",
        "    pyplot.imshow(mask[:, :, j], cmap=\"gray\", alpha=0.3)\n",
        "  \n",
        "  pyplot.subplot(111)\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title(\"Face to Text\")\n",
        "\n",
        "  ax = pyplot.gca()\n",
        "\n",
        "  face_centers = []\n",
        "  text_centers = []\n",
        "  frame_corners = []\n",
        "  count = 0\n",
        "\n",
        "  for id in class_ids:\n",
        "    box = rois[count]\n",
        "    count += 1\n",
        "\n",
        "    y1, x1, y2, x2 = box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "\n",
        "    if id == 1:\n",
        "      face_x = (x1 + x2)//2\n",
        "      face_y = (y1 + y2)//2\n",
        "      face_center = [face_x, face_y]\n",
        "      face_centers.append(face_center)\n",
        "\n",
        "      rect = Rectangle((x1, y1), width, height, fill=False, color=\"red\")\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "    elif id == 2:\n",
        "      text_x = (x1 + x2)//2\n",
        "      text_y = (y1 + y2)//2\n",
        "      text_center = [text_x, text_y]\n",
        "      text_centers.append(text_center)\n",
        "\n",
        "      rect = Rectangle((x1, y1), width, height, fill=False, color=\"yellow\")\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "    elif id == 3:\n",
        "      frame_corners.append([x1, x2, y1, y2])\n",
        "      rect = Rectangle((x1, y1), width, height, fill=False, color=\"violet\")\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "  faces_to_texts = []\n",
        "\n",
        "  for frame in frame_corners:\n",
        "    x1, x2, y1, y2 = frame\n",
        "    face_centers_filtered, text_centers_filtered = [], []\n",
        "    num_faces, num_text = 0, 0\n",
        "\n",
        "    for face in face_centers:\n",
        "      if face[0] < x2 and face[0] > x1 and face[1] < y2 and face[1] > y1:\n",
        "        num_faces += 1\n",
        "        face_centers_filtered.append(face)\n",
        "\n",
        "    for text in text_centers:\n",
        "      if text[0] < x2 and text[0] > x1 and text[1] < y2 and text[1] > y1:\n",
        "        num_text += 1\n",
        "        text_centers_filtered.append(text)\n",
        "    \n",
        "    if num_faces >= num_text:\n",
        "      for face in face_centers_filtered:\n",
        "        if text_centers_filtered:\n",
        "          nearest_text = text_centers_filtered[0]\n",
        "          shortest_x = abs(face[0] - nearest_text[0])\n",
        "          shortest_y = abs(face[1] - nearest_text[1])\n",
        "          shortest_distance = math.sqrt(shortest_x**2 + shortest_y**2)\n",
        "\n",
        "          for text in text_centers_filtered:\n",
        "            distance_x = abs(face[0] - text[0])\n",
        "            distance_y = abs(face[1] - text[1])\n",
        "            distance = math.sqrt(distance_x**2 + distance_y**2)\n",
        "\n",
        "            if distance < shortest_distance:\n",
        "              shortest_distance = distance\n",
        "              nearest_text = text\n",
        "\n",
        "          face_to_text = [face, nearest_text]\n",
        "          faces_to_texts.append(face_to_text)\n",
        "\n",
        "    elif num_faces < num_text:\n",
        "      for text in text_centers_filtered:\n",
        "        if face_centers_filtered:\n",
        "          nearest_face = face_centers_filtered[0]\n",
        "          shortest_x = abs(text[0] - nearest_face[0])\n",
        "          shortest_y = abs(text[1] - nearest_face[1])\n",
        "          shortest_distance = math.sqrt(shortest_x**2 + shortest_y**2)\n",
        "\n",
        "          for face in face_centers_filtered:\n",
        "            distance_x = abs(face[0] - text[0])\n",
        "            distance_y = abs(face[1] - text[1])\n",
        "            distance = math.sqrt(distance_x**2 + distance_y**2)\n",
        "\n",
        "            if distance < shortest_distance:\n",
        "              shortest_distance = distance\n",
        "              nearest_face = face\n",
        "\n",
        "          face_to_text = [nearest_face, text]\n",
        "          faces_to_texts.append(face_to_text)\n",
        "\n",
        "  for face_to_text in faces_to_texts:\n",
        "    face, text = face_to_text\n",
        "\n",
        "    face_x, face_y = face\n",
        "    text_x, text_y = text\n",
        "\n",
        "    length_x = abs(face_x - text_x)\n",
        "    length_y = abs(face_y - text_y)\n",
        "\n",
        "    if face_x > text_x: #face is to the right of text\n",
        "      length_x *= -1\n",
        "      \n",
        "    if face_y > text_y: #face is below text\n",
        "      length_y *= -1\n",
        "\n",
        "    arrow = Arrow(face_x, face_y, length_x, length_y, color=\"cornflowerblue\")\n",
        "    ax.add_patch(arrow)\n",
        "\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5PuyVVQrFdF"
      },
      "source": [
        "# Text Order Determination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGayiWpmmKtg"
      },
      "source": [
        "def order_frame_halves(unordered_frames):\n",
        "  ordered_frames = []\n",
        "  while unordered_frames:\n",
        "    for frame in unordered_frames:\n",
        "      for other_frame in unordered_frames:\n",
        "        if other_frame[3] < frame[1]: # if there is a frame above the current frame\n",
        "          break # the current frame is not the next frame to read\n",
        "      else:\n",
        "        ordered_frames.append(frame[:-1]) # the current frame is the next frame\n",
        "        unordered_frames.remove(frame)\n",
        "\n",
        "  return ordered_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foi7SnFaRScx"
      },
      "source": [
        "def order_text(dataset, image_id, img_width, cfg, model):\n",
        "  image = dataset.load_image(image_id)\n",
        "  mask, _ = dataset.load_mask(image_id)\n",
        "  scaled_image = mold_image(image, cfg)\n",
        "  sample = expand_dims(scaled_image, 0)\n",
        "\n",
        "  yhat = model.detect(sample, verbose=0)[0]\n",
        "  rois = list(yhat[\"rois\"])\n",
        "  class_ids = list(yhat[\"class_ids\"])\n",
        "\n",
        "  for j in range(mask.shape[2]):\n",
        "    pyplot.imshow(mask[:, :, j], cmap=\"gray\", alpha=0.3)\n",
        "  \n",
        "  pyplot.subplot(111)\n",
        "  pyplot.imshow(image)\n",
        "  pyplot.title(\"Order Text\")\n",
        "\n",
        "  ax = pyplot.gca()\n",
        "\n",
        "  text_centers = []\n",
        "  total_unordered_frames = []\n",
        "  count = 0\n",
        "\n",
        "  for id in class_ids:\n",
        "    box = rois[count]\n",
        "    count += 1\n",
        "\n",
        "    y1, x1, y2, x2 = box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "\n",
        "    if id == 2:\n",
        "      text_x = (x1 + x2)//2\n",
        "      text_y = (y1 + y2)//2\n",
        "      text_center = [text_x, text_y]\n",
        "      text_centers.append(text_center)\n",
        "\n",
        "      rect = Rectangle((x1, y1), width, height, fill=False, color=\"yellow\")\n",
        "      ax.add_patch(rect)\n",
        "    elif id == 3:\n",
        "      frame_x_center = (x1 + x2)//2\n",
        "      total_unordered_frames.append([x1, y1, x2, y2, frame_x_center]) # the corners are ordered this way to improve sorting later on\n",
        "\n",
        "  total_unordered_frames.sort(reverse=True)\n",
        "  ordered_frames = [] # 1st, 2nd, 3rd, ...\n",
        "\n",
        "  half_line = img_width//2\n",
        "\n",
        "  unordered_frames_first = [frame for frame in total_unordered_frames if frame[-1] > half_line] # frames to the right of half line\n",
        "  unordered_frames_second = [frame for frame in total_unordered_frames if frame[-1] <= half_line] # frames to the left of half line\n",
        "\n",
        "  ordered_frames_first = order_frame_halves(unordered_frames_first)\n",
        "  ordered_frames_second = order_frame_halves(unordered_frames_second)\n",
        "\n",
        "  index = 1\n",
        "  \n",
        "  for frame in ordered_frames_first:\n",
        "    x1, y1, x2, y2 = frame\n",
        "    text_centers_filtered = []\n",
        "\n",
        "    for text in text_centers:\n",
        "      if text[0] < x2 and text[0] > x1 and text[1] < y2 and text[1] > y1:\n",
        "        text_centers_filtered.append([text[0], -text[1]])\n",
        "    \n",
        "    text_centers_filtered.sort(reverse=True)\n",
        "    for text in text_centers_filtered:\n",
        "      pyplot.text(text[0], -text[1], index)\n",
        "      index += 1\n",
        "\n",
        "  for frame in ordered_frames_second:\n",
        "    x1, y1, x2, y2 = frame\n",
        "    text_centers_filtered = []\n",
        "\n",
        "    for text in text_centers:\n",
        "      if text[0] < x2 and text[0] > x1 and text[1] < y2 and text[1] > y1:\n",
        "        text_centers_filtered.append([text[0], -text[1]])\n",
        "    \n",
        "    text_centers_filtered.sort(reverse=True)\n",
        "    for text in text_centers_filtered:\n",
        "      pyplot.text(text[0], -text[1], index)\n",
        "      index += 1\n",
        "\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep0XuzD-tL8b"
      },
      "source": [
        "# Use Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89CXAA7tmiMa"
      },
      "source": [
        "dataset = test_set\n",
        "last_image_id = 0\n",
        "\n",
        "for book in sorted(p.books):\n",
        "  images_dir = root_dir + \"images/\" + book + \"/\"\n",
        "  annotations_dir = root_dir + \"annotations/\" + book + \"/\"\n",
        "\n",
        "  for img in sorted(listdir(images_dir)):\n",
        "    image_id = int(img[:-4])\n",
        "    current_image_id = image_id + last_image_id\n",
        "\n",
        "    xml_file = annotations_dir + \"new_\" + book + str(image_id) + \".xml\"\n",
        "\n",
        "    tree = ElementTree.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    faces = []\n",
        "    texts = []\n",
        "\n",
        "    for face in root.findall(\".//face\"):\n",
        "      faces.append(face)\n",
        "    \n",
        "    for text in root.findall(\".//text\"):\n",
        "      texts.append(text)\n",
        "    \n",
        "    if len(faces) < 1: #if there are no faces\n",
        "      continue\n",
        "    \n",
        "    if len(texts) < 1: #if there are no texts\n",
        "      continue\n",
        "\n",
        "    img_width = int(root.attrib[\"width\"]) # get width of page\n",
        "\n",
        "    arrow_face_text(dataset, current_image_id, cfg, model)\n",
        "    order_text(dataset, image_id, img_width, cfg, model)\n",
        "\n",
        "    print(book, current_image_id)\n",
        "\n",
        "  last_image_id = current_image_id + 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}